{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariMurotani/ARCamera/blob/master/git%40github.com%3AMariMurotani/ColabNotebooks.git\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-5OIuM_iUmP",
        "outputId": "6dc0e5b9-31ed-4a03-d85b-29483fd72fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 28 06:06:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P0             32W /   70W |     638MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V6ViOT-hHXdP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "7lW2WmOcZi4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7899bd-0cb7-49e5-b837-22f8c1cb2564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "id": "hU06Cf9MZ4UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2390e0e5-0e08-4449-9320-1d5393a9f2d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ImageEnhance\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/ImageEnhance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "n5-iemRenPlt"
      },
      "outputs": [],
      "source": [
        "#!model_zoo\n",
        "#!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_colorCAR_DFWB_s126w7_SwinIR-M_jpeg10.pth -P model_zoo/\n",
        "#!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/006_colorCAR_DFWB_s126w7_SwinIR-M_jpeg40.pth -P model_zoo/\n",
        "#!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise15.pth -P model_zoo/\n",
        "#!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/005_colorDN_DFWB_s128w8_SwinIR-M_noise50.pth -P model_zoo/\n",
        "#!wget https://github.com/JingyunLiang/SwinIR/releases/download/v0.0/001_classicalSR_DF2K_s64w8_SwinIR-M_x2.pth -P model_zoo/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ming053l/DRCT.git\n",
        "%cd DRCT"
      ],
      "metadata": {
        "id": "RFxPwUqtyBxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843fa24f-7503-4c09-fd75-b238c183437d"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DRCT' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Colab Notebooks/ImageEnhance/DRCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install basicsr timm"
      ],
      "metadata": {
        "id": "JbVyBnVdyEix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313d3ab8-97c3-4448-8fbf-b42900004f7b"
      },
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: basicsr==1.3.4.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.3.4.9)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (1.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (2.20.0a20250627)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from basicsr==1.3.4.9->-r requirements.txt (line 3)) (0.43.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr==1.3.4.9->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr==1.3.4.9->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr==1.3.4.9->-r requirements.txt (line 3)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr==1.3.4.9->-r requirements.txt (line 3)) (2025.6.15)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr==1.3.4.9->-r requirements.txt (line 3)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr==1.3.4.9->-r requirements.txt (line 3)) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr==1.3.4.9->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr==1.3.4.9->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr==1.3.4.9->-r requirements.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->basicsr==1.3.4.9->-r requirements.txt (line 3)) (4.3.8)\n",
            "Requirement already satisfied: basicsr in /usr/local/lib/python3.11/dist-packages (1.3.4.9)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.0.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from basicsr) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from basicsr) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from basicsr) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.32.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from basicsr) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from basicsr) (1.15.3)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.20.0a20250627)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from basicsr) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from basicsr) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from basicsr) (4.67.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from basicsr) (0.43.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.33.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->basicsr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7->basicsr) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->basicsr) (2025.6.15)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->basicsr) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly->basicsr) (3.1.3)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->basicsr) (4.3.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly->basicsr) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://github.com/ming053l/DRCT/releases/download/v1.0/DRCT_L_X4.pth -O model_zoo/DRCT_L_X4.pth"
      ],
      "metadata": {
        "id": "inKzGdXA6Eth"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "id": "IEaD0UN7nYpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7c0716-33c5-4b24-fd01-e745db682ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ImageEnhance\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/ImageEnhance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bHoAl_x5n5w",
        "outputId": "21b50bb6-83ef-472e-9150-fe37a32f2cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU3tpZAQeXbN",
        "outputId": "6fb89536-de8e-4ff2-ac85-2768412220cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SwinIR' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JingyunLiang/SwinIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {
        "id": "Ib5dJp0rBvLx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "from scipy.ndimage import map_coordinates\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from scipy.interpolate import PchipInterpolator\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import sys\n",
        "sys.path.append(\"SwinIR\")\n",
        "from models.network_swinir import SwinIR\n",
        "\n",
        "sys.path.append(\"DRCT\")\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
        "from drct.archs.DRCT_arch import DRCT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {
        "id": "Iax2u7pHMkmz"
      },
      "outputs": [],
      "source": [
        "def load_swinir_model_custom(model_path):\n",
        "    model = SwinIR(\n",
        "        upscale=2,\n",
        "        in_chans=3,\n",
        "        img_size=64,\n",
        "        window_size=8,\n",
        "        img_range=1.0,\n",
        "        depths=[6]*6,\n",
        "        embed_dim=180,\n",
        "        num_heads=[6]*6,\n",
        "        mlp_ratio=2,\n",
        "        upsampler='pixelshuffle',\n",
        "        resi_connection='1conv'\n",
        "    )\n",
        "    state_dict = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "    if 'params' in state_dict:\n",
        "        model.load_state_dict(state_dict['params'], strict=True)\n",
        "    else:\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "    model = model.to(\"cuda\")\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model_scale = load_swinir_model_custom(\n",
        "    'model_zoo/001_classicalSR_DF2K_s64w8_SwinIR-M_x2.pth'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {
        "id": "ALVK9lI5-1Fq"
      },
      "outputs": [],
      "source": [
        "def load_swinir_denoise_model(model_path):\n",
        "    model = SwinIR(\n",
        "        upscale=1,\n",
        "        in_chans=3,\n",
        "        img_size=128,\n",
        "        window_size=8,\n",
        "        img_range=1.0,\n",
        "        depths=[6, 6, 6, 6, 6, 6],\n",
        "        embed_dim=180,  # ← ここがポイント\n",
        "        num_heads=[6, 6, 6, 6, 6, 6],\n",
        "        mlp_ratio=2,\n",
        "        upsampler='',\n",
        "        resi_connection='1conv'\n",
        "    )\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    state_dict = torch.load(model_path, map_location=device)\n",
        "\n",
        "    if 'params' in state_dict:\n",
        "        state_dict = state_dict['params']\n",
        "\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model_denoise = load_swinir_denoise_model(\n",
        "  'model_zoo/005_colorDN_DFWB_s128w8_SwinIR-M_noise15.pth'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_drct_model(ckpt_path: str, device=\"cuda\"):\n",
        "    model = DRCT(\n",
        "        upscale=4,\n",
        "        in_chans=3,\n",
        "        img_size=64,\n",
        "        window_size=8,\n",
        "        embed_dim=180,\n",
        "        depths=[2, 2, 18, 2],\n",
        "        num_heads=[6, 12, 24, 48],\n",
        "        mlp_ratio=4\n",
        "    )\n",
        "\n",
        "    # checkpoint全体をロード\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    return model\n",
        "\n",
        "drct_model = load_drct_model(\"model_zoo/DRCT-L_X4.pth\", device=\"cuda\")"
      ],
      "metadata": {
        "id": "tqqMfzd43G7D"
      },
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "metadata": {
        "id": "52Vt8lb2pnWo"
      },
      "outputs": [],
      "source": [
        "def infer_swinir(model, image_np):\n",
        "    \"\"\"\n",
        "    SwinIRモデルで画像を推論し、結果をNumPy配列として返す。\n",
        "    \"\"\"\n",
        "    device = next(model.parameters()).device  # モデルが存在するdeviceを取得\n",
        "    img = transforms.ToTensor()(Image.fromarray(image_np)).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img).clamp(0, 1)\n",
        "\n",
        "    out_img = output.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "    out_img = (out_img * 255.0).round().astype(np.uint8)\n",
        "\n",
        "    return out_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {
        "id": "KEZOVaEPEEr5"
      },
      "outputs": [],
      "source": [
        "def infer_swinir_denoise(model, image_np):\n",
        "    \"\"\"\n",
        "    SwinIRノイズ除去モデルで画像を推論し、結果をNumPy配列として返す。\n",
        "    \"\"\"\n",
        "    # 入力検査と前処理\n",
        "    if image_np.dtype != np.uint8:\n",
        "        image_np = np.clip(image_np, 0, 255).astype(np.uint8)\n",
        "    if image_np.ndim != 3 or image_np.shape[2] != 3:\n",
        "        raise ValueError(f\"Expected image with shape (H, W, 3), got {image_np.shape}\")\n",
        "    if image_np.shape[0] < 2 or image_np.shape[1] < 2:\n",
        "        raise ValueError(f\"Image too small for processing: {image_np.shape}\")\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    img = transforms.ToTensor()(Image.fromarray(image_np)).unsqueeze(0).to(device)\n",
        "\n",
        "    # 推論\n",
        "    with torch.no_grad():\n",
        "        output = model(img).clamp(0, 1)\n",
        "\n",
        "    out_img = output.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "    out_img = (out_img * 255.0).round().astype(np.uint8)\n",
        "    return out_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_drct_on_image(model, input_image_np, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    DRCTモデルによる画像推論（正規化含む、NumPy限定）\n",
        "    \"\"\"\n",
        "    if input_image_np.dtype != np.float32:\n",
        "        input_image_np = input_image_np.astype(np.float32) / 255.0\n",
        "\n",
        "    tensor = torch.from_numpy(input_image_np.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(tensor)\n",
        "\n",
        "    out_np = output.squeeze(0).cpu().clamp(0, 1).numpy().transpose(1, 2, 0)\n",
        "    return (out_np * 255).round().astype(np.uint8)"
      ],
      "metadata": {
        "id": "F-yIJLzB3zkK"
      },
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "id": "Dq311H3t7xDu"
      },
      "outputs": [],
      "source": [
        "def resize_to_target(img, target_width=1712):\n",
        "    h, w = img.shape[:2]\n",
        "    max_dim = max(h, w)\n",
        "\n",
        "    if max_dim > target_width * 4:\n",
        "        # 縮小\n",
        "        scale = target_width / max_dim\n",
        "        interpolation = cv2.INTER_AREA\n",
        "    else:\n",
        "        # 拡大\n",
        "        scale = target_width / max_dim\n",
        "        interpolation = cv2.INTER_CUBIC\n",
        "\n",
        "    new_size = (int(w * scale), int(h * scale))\n",
        "    resized = cv2.resize(img, new_size, interpolation=interpolation)\n",
        "\n",
        "    return resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {
        "id": "JNzlYkQH2wZ-"
      },
      "outputs": [],
      "source": [
        "def sharpen_image(img, alpha=1.0):\n",
        "    \"\"\"\n",
        "    シャープネス処理を行う関数。\n",
        "\n",
        "    Parameters:\n",
        "        img: 入力画像 (NumPy 配列, RGB)\n",
        "        alpha: シャープネス強度（通常は 0.5〜1.5）\n",
        "\n",
        "    Returns:\n",
        "        シャープ処理後の画像\n",
        "    \"\"\"\n",
        "    blurred = cv2.GaussianBlur(img, (0, 0), sigmaX=1.0)\n",
        "    sharpened = cv2.addWeighted(img, 1 + alpha, blurred, -alpha, 0)\n",
        "    return np.clip(sharpened, 0, 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {
        "id": "p1MfcKMIzOPv"
      },
      "outputs": [],
      "source": [
        "def denoise_with_opencv(img, h=10):\n",
        "    \"\"\"\n",
        "    OpenCVの非局所平均を使った軽めのノイズ除去\n",
        "    h: フィルタの強さ（大きいほど強力）\n",
        "    \"\"\"\n",
        "    return cv2.fastNlMeansDenoisingColored(img, None, h, h, 7, 21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {
        "id": "lYuh7GRpP32F"
      },
      "outputs": [],
      "source": [
        "# グレースケール化してヒストグラム取得（露出判定用）\n",
        "def calc_image_hist(img_color):\n",
        "  \"\"\"\n",
        "  カラー画像からグレースケール変換を行い、ヒストグラムを計算して\n",
        "  最も頻度の高い輝度値（ピーク値）を返す関数。\n",
        "\n",
        "  Parameters:\n",
        "  - img_color: np.ndarray\n",
        "      BGR形式のカラー画像（OpenCVで読み込んだ画像）\n",
        "\n",
        "  Returns:\n",
        "  - peak: int\n",
        "      グレースケール画像のヒストグラムにおける最大頻度の輝度値（0〜255）\n",
        "  - hist: np.ndarray\n",
        "      輝度ヒストグラム（256次元の1次元配列）\n",
        "  - lift_amoubt: int\n",
        "      輝度ヒストグラム（256次元の1次元配列）\n",
        "  \"\"\"\n",
        "  gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
        "  hist = cv2.calcHist([gray], [0], None, [256], [0, 256]).flatten()\n",
        "  peak = np.argmax(hist)\n",
        "  lift_amount = compute_adaptive_lift(gray, peak)\n",
        "\n",
        "  return peak, hist, lift_amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {
        "id": "Fu0EZvRHqnnq"
      },
      "outputs": [],
      "source": [
        "def compute_adaptive_lift(gray_img: np.ndarray, peak: int, max_lift=60, min_lift=10) -> int:\n",
        "    \"\"\"\n",
        "    輝度画像に基づいて白飛びを抑えるリフト量を決定\n",
        "\n",
        "    Parameters:\n",
        "    - gray_img: グレースケール画像（0〜255）\n",
        "    - peak: ヒストグラムピーク値\n",
        "    - max_lift: 最大リフト量（デフォルト: 60）\n",
        "    - min_lift: 最小リフト量（デフォルト: 10）\n",
        "\n",
        "    Returns:\n",
        "    - lift_amount: 推定されたリフト量\n",
        "    \"\"\"\n",
        "    # 上位5%輝度の中央値をとる\n",
        "    high_percentile_value = np.percentile(gray_img, 95)\n",
        "\n",
        "    # この値が230以上ならリフト量を抑制、低ければリフトを許容\n",
        "    weight = 1.0 - (high_percentile_value - 128) / (255 - 128)\n",
        "    weight = np.clip(weight, 0.0, 1.0)\n",
        "\n",
        "    lift_amount = int(min_lift + (max_lift - min_lift) * weight)\n",
        "    print(f\"lift_amount: {lift_amount}\")\n",
        "\n",
        "    return lift_amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 452,
      "metadata": {
        "id": "ynrQj0bbmu9L"
      },
      "outputs": [],
      "source": [
        "def show_sampled_image(hist, lut, peak, lift_amount, img_color, adjusted_color, denoised_cv, sharpend_cv):\n",
        "  # トーンカーブ表示を2番目の軸（axes[1]）に埋め込むように変更\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(18, 5))\n",
        "\n",
        "  # 0: 元画像\n",
        "  axes[0].imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))\n",
        "  axes[0].set_title(\"Original\")\n",
        "  axes[0].axis(\"off\")\n",
        "\n",
        "  # 1: ヒストグラムとトーンカーブの重ね描き\n",
        "  axes[1].bar(np.arange(256), hist / hist.max() * 255, color='gray', alpha=0.6, label='Histogram')\n",
        "  axes[1].plot(np.arange(256), lut, color='blue', label='Tone Curve')\n",
        "  axes[1].plot([0, 255], [0, 255], '--', color='black', linewidth=1, label='Identity')\n",
        "  axes[1].set_title(f\"Histogram & Tone Curve (peak: {peak})\")\n",
        "  axes[1].plot(peak, peak+lift_amount, 'ro', label='Control Points')\n",
        "  axes[1].legend()\n",
        "  axes[1].set_xlim([0, 255])\n",
        "  axes[1].set_ylim([0, 255])\n",
        "  axes[1].grid(True)\n",
        "\n",
        "  # 2: トーンカーブ補正後画像\n",
        "  axes[2].imshow(cv2.cvtColor(adjusted_color, cv2.COLOR_BGR2RGB))\n",
        "  axes[2].set_title(f\"Tone Curve Adjusted\")\n",
        "  axes[2].axis(\"off\")\n",
        "\n",
        "  # 3: デノイズ済画像（仮）\n",
        "  axes[3].imshow(cv2.cvtColor(denoised_cv, cv2.COLOR_BGR2RGB))\n",
        "  axes[3].set_title(\"Denoised\")\n",
        "  axes[3].axis(\"off\")\n",
        "\n",
        "  # 4: シャープ化画像（仮）\n",
        "  axes[4].imshow(cv2.cvtColor(sharpend_cv, cv2.COLOR_BGR2RGB))\n",
        "  axes[4].set_title(\"Sharpened\")\n",
        "  axes[4].axis(\"off\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 453,
      "metadata": {
        "id": "lkpC4_0gQfdi"
      },
      "outputs": [],
      "source": [
        "def apply_tone_curve_by_peak(img_bgr: np.ndarray, peak: int, lift_amount: int = 50, interpolation: str = 'pchip') -> np.ndarray:\n",
        "    \"\"\"\n",
        "    画像に対して、輝度ヒストグラムのピーク位置を中心にトーンカーブ補正を行い、\n",
        "    トーンカーブとヒストグラムをオーバーレイ表示する。\n",
        "\n",
        "    Parameters:\n",
        "    - img_bgr: 入力画像（BGR形式）\n",
        "    - peak: ヒストグラムのピーク位置（0〜255）\n",
        "    - lift_amount: ピークに対して持ち上げる量（デフォルトは+50）\n",
        "\n",
        "    Returns:\n",
        "    - トーンカーブ補正後のBGR画像と LUT（1次元 np.uint8 配列）\n",
        "    \"\"\"\n",
        "    # 制御点の設定\n",
        "    x = np.array([0, peak, 255])\n",
        "    y = np.array([0, np.clip(peak + lift_amount, 0, 255), 255])\n",
        "\n",
        "    # 小さい順にソート\n",
        "    sort_idx = np.argsort(x)\n",
        "    x_sorted = x[sort_idx]\n",
        "    y_sorted = y[sort_idx]\n",
        "\n",
        "    # 重複を除く（xがstrictly increasingになるように）\n",
        "    x_unique, unique_indices = np.unique(x_sorted, return_index=True)\n",
        "    y_unique = y_sorted[unique_indices]\n",
        "\n",
        "    # トーンカーブ関数生成（PCHIP）\n",
        "    pchip = PchipInterpolator(x_unique, y_unique)\n",
        "\n",
        "    # LUT生成\n",
        "    curve = pchip(np.arange(256))\n",
        "    lut = np.clip(curve, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # トーンカーブ補正適用\n",
        "    channels = cv2.split(img_bgr)\n",
        "    adjusted_channels = [cv2.LUT(c, lut) for c in channels]\n",
        "    adjusted_img = cv2.merge(adjusted_channels)\n",
        "\n",
        "    return adjusted_img, lut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {
        "id": "hCrL4uvTRnOR"
      },
      "outputs": [],
      "source": [
        "def split_tiles(img, tile_size=512, overlap=64):\n",
        "    h, w = img.shape[:2]\n",
        "    stride = tile_size - overlap\n",
        "    tiles = []\n",
        "\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            y1, x1 = y, x\n",
        "            y2 = min(y1 + tile_size, h)\n",
        "            x2 = min(x1 + tile_size, w)\n",
        "\n",
        "            tile = img[y1:y2, x1:x2]\n",
        "\n",
        "            # 足りない部分をパディング\n",
        "            pad_bottom = tile_size - tile.shape[0]\n",
        "            pad_right = tile_size - tile.shape[1]\n",
        "            if pad_bottom > 0 or pad_right > 0:\n",
        "                tile = cv2.copyMakeBorder(tile, 0, pad_bottom, 0, pad_right,\n",
        "                                          borderType=cv2.BORDER_REFLECT_101)\n",
        "            tiles.append(((y1, x1), tile))\n",
        "\n",
        "    return tiles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_tiles_for_drct(img, tile_size=512, overlap=64, window_size=8):\n",
        "    h, w = img.shape[:2]\n",
        "    stride = tile_size - overlap\n",
        "    tiles = []\n",
        "\n",
        "    for y in range(0, h, stride):\n",
        "        for x in range(0, w, stride):\n",
        "            y1, x1 = y, x\n",
        "            y2 = y1 + tile_size\n",
        "            x2 = x1 + tile_size\n",
        "\n",
        "            # tile をクロップし、足りなければリフレクトパディング\n",
        "            tile = img[y1:min(y2, h), x1:min(x2, w)]\n",
        "            pad_bottom = max(0, y2 - h)\n",
        "            pad_right = max(0, x2 - w)\n",
        "\n",
        "            # tile サイズを window_size の倍数に調整\n",
        "            pad_h = (window_size - tile.shape[0] % window_size) % window_size\n",
        "            pad_w = (window_size - tile.shape[1] % window_size) % window_size\n",
        "            pad_bottom += pad_h\n",
        "            pad_right += pad_w\n",
        "\n",
        "            tile = cv2.copyMakeBorder(\n",
        "                tile, 0, pad_bottom, 0, pad_right,\n",
        "                borderType=cv2.BORDER_REFLECT_101\n",
        "            )\n",
        "\n",
        "            tiles.append(((y1, x1), tile))\n",
        "\n",
        "    return tiles"
      ],
      "metadata": {
        "id": "6liRxInv_d5k"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image_with_swinir_parallel(img, tile_size=384, overlap=64, scale=2, max_workers=4):\n",
        "    \"\"\"\n",
        "    画像をタイル分割して並列でSwinIR系モデル（例: DRCT）を推論し、オプションでDenoise処理し、再結合する。\n",
        "\n",
        "    Parameters:\n",
        "        img (np.ndarray): 入力画像 (H, W, 3), RGB or BGR\n",
        "        tile_size (int): タイル1辺のサイズ（推奨: 384）\n",
        "        overlap (int): タイル間のオーバーラップ量\n",
        "        scale (int): 拡大スケール（例: 2）\n",
        "        max_workers (int): 並列推論のスレッド数\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 超解像後の画像 (H*scale, W*scale, 3), dtype=uint8\n",
        "    \"\"\"\n",
        "    tiles = split_tiles_for_drct(img, tile_size, overlap)\n",
        "    h, w = img.shape[:2]\n",
        "    out_h, out_w = h * scale, w * scale\n",
        "    result = np.zeros((out_h, out_w, 3), dtype=np.float32)\n",
        "    count_map = np.zeros_like(result)\n",
        "\n",
        "    tile_coords = [(y, x) for (y, x), _ in tiles]\n",
        "    tile_imgs = [tile for _, tile in tiles]\n",
        "\n",
        "    # 並列 Super-Resolution\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        upscaled_tiles = list(executor.map(lambda t: infer_drct_on_image(drct_model, t).astype(np.float32), tile_imgs))\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # オプション: Denoise\n",
        "    upscaled_tiles = [infer_swinir_denoise(model_denoise, tile.astype(np.uint8)).astype(np.float32) for tile in upscaled_tiles]\n",
        "\n",
        "    for (y, x), tile in zip(tile_coords, upscaled_tiles):\n",
        "        py, px = y * scale, x * scale\n",
        "        th, tw = tile.shape[:2]\n",
        "        y1, y2 = py, min(py + th, result.shape[0])\n",
        "        x1, x2 = px, min(px + tw, result.shape[1])\n",
        "        tile = tile[:y2 - y1, :x2 - x1]\n",
        "        if y2 > y1 and x2 > x1:\n",
        "            result[y1:y2, x1:x2] += tile\n",
        "            count_map[y1:y2, x1:x2] += 1.0\n",
        "\n",
        "    merged = result / (count_map + 1e-6)\n",
        "    return np.clip(merged, 0, 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "XtCmTBUMIEqf"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bejWBSr0KHSr",
        "outputId": "b41a32cc-cbdd-414f-cc7a-01989a45a7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ImageEnhance\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/ImageEnhance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {
        "id": "J8_TUUHJ_YC2"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Auto Image Correction\n",
        "# トーンカーブを利用した画像の補正\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "egaXfMWynFId",
        "outputId": "7e768208-171e-494b-9ed5-b03c5fc2ad4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lift_amount: 31\n",
            "Underexposed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: 'SwinIR' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-459-2733041869.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0moriginal_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madjusted_color\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;31m# タイル上にしてアップスケーリング\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image_with_swinir_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjusted_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;31m# デノイズ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-456-686903387.py\u001b[0m in \u001b[0;36mprocess_image_with_swinir_parallel\u001b[0;34m(img, tile_size, overlap, scale, max_workers)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m超解像後の画像\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_tiles_for_drct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mout_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-455-3468452051.py\u001b[0m in \u001b[0;36msplit_tiles_for_drct\u001b[0;34m(img, tile_size, overlap, window_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_tiles_for_drct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtile_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'SwinIR' and 'int'"
          ]
        }
      ],
      "source": [
        "#for entry in os.listdir(\"./inputs\"):\n",
        "for entry in [\"_DSC0704.jpg\"]:\n",
        "  if entry == \".\" or entry == \"..\":\n",
        "    continue\n",
        "\n",
        "  plt.show(entry)\n",
        "\n",
        "  # おまじない\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # カラー画像の読み込み\n",
        "  img_path = f\"inputs/{entry}\"\n",
        "  img_color = cv2.imread(img_path)\n",
        "\n",
        "  # 明るさカテゴリ分類\n",
        "  peak, hist, lift_amount = calc_image_hist(img_color)\n",
        "\n",
        "  # 初期値\n",
        "  adjusted_color = np.zeros((512, 512, 3), dtype=np.uint8)\n",
        "\n",
        "  # トーンカーブ補正\n",
        "  if peak < 85:\n",
        "      exposure_status = \"Underexposed\"\n",
        "      adjusted_color, lut = apply_tone_curve_by_peak(img_color, peak, lift_amount=lift_amount)\n",
        "  elif peak > 170:\n",
        "      print(f\"peak: {peak}\")\n",
        "      exposure_status = \"Overexposed\"\n",
        "      adjusted_color, lut = apply_tone_curve_by_peak(img_color, peak, lift_amount=-lift_amount)\n",
        "  else:\n",
        "      exposure_status = \"Properly exposed\"\n",
        "\n",
        "  print(exposure_status)\n",
        "\n",
        "  original_size = adjusted_color.shape\n",
        "  # タイル上にしてアップスケーリング\n",
        "  processed = process_image_with_swinir_parallel(adjusted_color, model_scale)\n",
        "\n",
        "  # デノイズ\n",
        "  denoised_cv = denoise_with_opencv(processed, h=5)\n",
        "  denoised_cv = cv2.resize(denoised_cv, (original_size[1], original_size[0]), interpolation=cv2.INTER_CUBIC)\n",
        "  # シャープ\n",
        "  sharpend_cv = sharpen_image(processed, alpha=0.2)\n",
        "  sharpend_cv = cv2.resize(sharpend_cv, (original_size[1], original_size[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "  # 結果表示\n",
        "  show_sampled_image(hist, lut, peak, lift_amount, img_color, processed, denoised_cv, sharpend_cv)\n",
        "\n",
        "  # ファイルに保存\n",
        "  output_path = \"./outputs/\" + img_path.split('/')[-1].split('.')[0]\n",
        "  cv2.imwrite(output_path + \"denoised.jpg\", denoised_cv)\n",
        "  cv2.imwrite(output_path + \"sharpen.jpg\", sharpend_cv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI8EmgxsgaC5"
      },
      "outputs": [],
      "source": [
        "def show_sampled_image_hdr(hist, img_color, adjusted_color, denoised_cv, sharpend_cv):\n",
        "  # トーンカーブ表示を2番目の軸（axes[1]）に埋め込むように変更\n",
        "  fig, axes = plt.subplots(1, 5, figsize=(18, 5))\n",
        "\n",
        "  # 0: 元画像\n",
        "  axes[0].imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))\n",
        "  axes[0].set_title(\"Original\")\n",
        "  axes[0].axis(\"off\")\n",
        "\n",
        "  # 1: ヒストグラムとトーンカーブの重ね描き\n",
        "  axes[1].bar(np.arange(256), hist / hist.max() * 255, color='gray', alpha=0.6, label='Histogram')\n",
        "  axes[1].plot([0, 255], [0, 255], '--', color='black', linewidth=1, label='Identity')\n",
        "  axes[1].set_title(f\"Histogram & Tone Curve (peak: {peak})\")\n",
        "  axes[1].legend()\n",
        "  axes[1].set_xlim([0, 255])\n",
        "  axes[1].set_ylim([0, 255])\n",
        "  axes[1].grid(True)\n",
        "\n",
        "  # 2: マスク画像\n",
        "  axes[2].imshow(cv2.cvtColor(adjusted_color, cv2.COLOR_BGR2RGB))\n",
        "  axes[2].set_title(f\"Mask\")\n",
        "  axes[2].axis(\"off\")\n",
        "\n",
        "  # 3: デノイズ済画像（仮）\n",
        "  axes[3].imshow(cv2.cvtColor(denoised_cv, cv2.COLOR_BGR2RGB))\n",
        "  axes[3].set_title(\"Denoised\")\n",
        "  axes[3].axis(\"off\")\n",
        "\n",
        "  # 4: デノイズ&シャープ済画像（仮）\n",
        "  axes[4].imshow(cv2.cvtColor(sharpend_cv, cv2.COLOR_BGR2RGB))\n",
        "  axes[4].set_title(\"Denoised&Sharped\")\n",
        "  axes[4].axis(\"off\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akekABmOiDoz"
      },
      "outputs": [],
      "source": [
        "def find_valley_in_range(image: np.ndarray, min_val: int = 50, max_val: int = 200,\n",
        "                         smooth_kernel_size: int = 5) -> int:\n",
        "    \"\"\"\n",
        "    グレースケール画像のヒストグラムから、指定範囲内の谷（最小値）を探してインデックス（輝度値）を返す。\n",
        "\n",
        "    Parameters:\n",
        "    - image: 画像 (np.ndarray)\n",
        "    - min_val: 検索範囲の下限（輝度）\n",
        "    - max_val: 検索範囲の上限（輝度）\n",
        "    - smooth_kernel_size: 平滑化のカーネルサイズ\n",
        "\n",
        "    Returns:\n",
        "    - 輝度の谷位置（int）\n",
        "    \"\"\"\n",
        "    # ヒストグラム生成・平滑化\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    hist = cv2.calcHist([image], [0], None, [256], [0, 256]).flatten()\n",
        "    hist_smooth = np.convolve(hist, np.ones(smooth_kernel_size) / smooth_kernel_size, mode='same')\n",
        "\n",
        "    # 指定範囲の最小値インデックス\n",
        "    valley_range = hist_smooth[min_val:max_val]\n",
        "    valley_index = int(np.argmin(valley_range) + min_val)\n",
        "\n",
        "    # マスク作成（上位10%の明るい領域を1に）\n",
        "    # 画像の谷の部分\n",
        "    mask = np.where(gray >= valley_index, 255, 0).astype(np.uint8)\n",
        "\n",
        "    return valley_index, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg6E9aFBEEZQ"
      },
      "outputs": [],
      "source": [
        "#for entry in os.listdir(\"./inputs\"):\n",
        "for entry in [\"_DSC0704.jpg\"]:\n",
        "  if entry == \".\" or entry == \"..\":\n",
        "    continue\n",
        "\n",
        "  # おまじない\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # カラー画像の読み込み\n",
        "  img_path = f\"inputs/{entry}\"\n",
        "  img_color = cv2.imread(img_path)\n",
        "\n",
        "  # 輝度画像に変換（グレースケール）\n",
        "  peak, hist, lift_amount = calc_image_hist(img_color)\n",
        "  new_lift_amount = lift_amount*1.5\n",
        "  # とりあえず、明るめと言う意味で1.5倍にする、もっと的確なロジックんにしていいはず\n",
        "  adjusted_image, lut = apply_tone_curve_by_peak(img_color, peak, lift_amount=new_lift_amount)\n",
        "\n",
        "  # 1. グレースケールマスクを用意（255 or 0 の2値）\n",
        "  valley, mask = find_valley_in_range(img_color, min_val=70, max_val=180)\n",
        "\n",
        "  # 2. ガウシアンブラーでマスクをぼかす\n",
        "  blurred_mask = cv2.GaussianBlur(mask, (21, 21), sigmaX=10)\n",
        "\n",
        "  # 3. 正規化（0〜1.0）＆チャンネル拡張\n",
        "  alpha = blurred_mask.astype(np.float32) / 255.0\n",
        "  alpha = np.repeat(alpha[..., None], 3, axis=2)  # (H, W, 3)\n",
        "  plt.imshow(alpha)\n",
        "\n",
        "  # 4. アルファブレンド\n",
        "  blended = alpha * img_color.astype(np.float32) + (1 - alpha) * adjusted_image.astype(np.float32)\n",
        "  blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
        "  original_size = blended.shape\n",
        "\n",
        "  # タイル上にしてアップスケーリング\n",
        "  processed = process_image_with_swinir_parallel(blended, model_scale)\n",
        "\n",
        "  # デノイズ\n",
        "  denoised_cv = denoise_with_opencv(processed, h=5)\n",
        "  denoised_cv = cv2.resize(denoised_cv, (original_size[1], original_size[0]), interpolation=cv2.INTER_CUBIC)\n",
        "  # シャープ\n",
        "  sharpend_cv = sharpen_image(processed, alpha=0.2)\n",
        "  sharpend_cv = cv2.resize(sharpend_cv, (original_size[1], original_size[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "  # 結果表示\n",
        "  show_sampled_image_hdr(hist, img_color, mask, blended, sharpend_cv)\n",
        "\n",
        "  # ファイルに保存\n",
        "  output_path = \"./outputs/\" + img_path.split('/')[-1].split('.')[0]\n",
        "  cv2.imwrite(output_path + \"_hdr_denoised.jpg\", denoised_cv)\n",
        "  cv2.imwrite(output_path + \"_hdr_sharpen.jpg\", sharpend_cv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tZLDdybjjk2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1qbLUKtw941tRPAm9GWNBhGRNY83z08TQ",
      "authorship_tag": "ABX9TyPEbvaNRnU5LsoTtIYWMHLu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}